{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'inpainting_gmcnn' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/shepnerd/inpainting_gmcnn.git\n",
    "\n",
    "!cd inpainting_gmcnn/pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'gpu_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/pratyush/Desktop/PreCog/TASK2/celebahq256_rect/10_net_GM.pth\u001b[39m\u001b[38;5;124m'\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Create an instance of your model\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mInpaintingModel_GMCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust parameters as needed\u001b[39;00m\n\u001b[1;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Set the model to evaluation mode\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/PreCog/TASK2/inpainting_gmcnn/pytorch/model/net.py:213\u001b[0m, in \u001b[0;36mInpaintingModel_GMCNN.__init__\u001b[0;34m(self, in_channels, act, norm, opt)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28msuper\u001b[39m(InpaintingModel_GMCNN, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt \u001b[38;5;241m=\u001b[39m opt\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfidence_mask_layer \u001b[38;5;241m=\u001b[39m ConfidenceDrivenMaskLayer()\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetGM \u001b[38;5;241m=\u001b[39m GMCNN(in_channels, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, cnum\u001b[38;5;241m=\u001b[39mopt\u001b[38;5;241m.\u001b[39mg_cnum, act\u001b[38;5;241m=\u001b[39mact, norm\u001b[38;5;241m=\u001b[39mnorm)\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[0;32m~/Desktop/PreCog/TASK2/inpainting_gmcnn/pytorch/model/basemodel.py:12\u001b[0m, in \u001b[0;36mBaseModel.init\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit\u001b[39m(\u001b[38;5;28mself\u001b[39m, opt):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt \u001b[38;5;241m=\u001b[39m opt\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_ids \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpu_ids\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mmodel_folder\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_ids[\u001b[38;5;241m0\u001b[39m])) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_ids \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'gpu_ids'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "# Set the desired directory path\n",
    "new_directory = \"/home/pratyush/Desktop/PreCog/TASK2/inpainting_gmcnn/pytorch\"\n",
    "\n",
    "os.chdir(new_directory)\n",
    "\n",
    "from model.net import InpaintingModel_GMCNN  # Import your model class\n",
    "\n",
    "# Load the state dictionary\n",
    "state_dict = torch.load('/home/pratyush/Desktop/PreCog/TASK2/celebahq256_rect/10_net_GM.pth', map_location=torch.device('cuda'))\n",
    "\n",
    "# Create an instance of your model\n",
    "model = InpaintingModel_GMCNN(in_channels=4, opt=None)  # Adjust parameters as needed\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Define preprocessing transform\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load and preprocess test images\n",
    "test_images_paths = [\"/home/pratyush/Desktop/PreCog/hateful_memes/img/01364.png\"]  # Specify the paths to your test images\n",
    "test_images = [preprocess(Image.open(img_path).convert(\"RGB\")) for img_path in test_images_paths]\n",
    "\n",
    "# Convert the images to a batch tensor\n",
    "test_images = torch.stack(test_images)\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    results = model(test_images)\n",
    "\n",
    "# Post-process and save or display results\n",
    "for i, result in enumerate(results):\n",
    "    result = result.numpy().transpose(1, 2, 0)\n",
    "    result = ((result + 1) / 2) * 255  # Assuming the output is in the range [-1, 1]\n",
    "    result = result.astype(np.uint8)\n",
    "\n",
    "    # Save the results as images\n",
    "    cv2.imwrite(f\"result_{i}.jpg\", cv2.cvtColor(result, cv2.COLOR_RGB2BGR))\n",
    "    # Or display the results using OpenCV imshow() or any other visualization method\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
